{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **B. Teks Summarization**\n",
        "\n"
      ],
      "metadata": {
        "id": "hBCpKDekxnDb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teks summarization adalah suatu metode komputasional yang bertujuan untuk membuat ringkasan atau cuplikan singkat dari teks yang lebih panjang atau kompleks. Tujuan utamanya adalah untuk menyajikan informasi penting tanpa kehilangan makna atau esensi dari teks asli. Ada dua jenis pendekatan utama dalam teks summarization: ekstraktif dan abstraktif.\n",
        "\n",
        "1. **Ekstraktif:**\n",
        "   - Pendekatan ekstraktif membuat ringkasan dengan mengekstrak frasa atau kalimat yang dianggap paling penting dari teks asli.\n",
        "   - Sistem melakukan analisis terhadap teks, menilai pentingnya setiap kalimat, dan memilih kalimat-kalimat tersebut untuk membentuk ringkasan.\n",
        "   - Keuntungan dari pendekatan ini adalah kesesuaian langsung dengan teks sumber, namun bisa kurang koheren karena hanya menggabungkan kalimat-kalimat yang sudah ada.\n",
        "\n",
        "2. **Abstraktif:**\n",
        "   - Pendekatan abstraktif lebih canggih karena sistem menciptakan ringkasan baru yang mungkin tidak ada dalam teks sumber.\n",
        "   - Sistem ini memahami makna dan konteks dari teks, lalu menggunakan kata-kata atau kalimat baru untuk merangkum informasi.\n",
        "   - Meskipun lebih fleksibel, abstraktif summarization dapat menjadi lebih kompleks karena memerlukan pemahaman yang lebih mendalam terhadap isi teks.\n",
        "\n",
        "Aplikasi teks summarization melibatkan sejumlah kegiatan, termasuk:\n",
        "\n",
        "- **Cepat Mencari Informasi:** Memungkinkan pengguna untuk mendapatkan ringkasan cepat dari teks panjang, sangat berguna dalam pencarian informasi di internet.\n",
        "  \n",
        "- **Pemrosesan Bahasa Alami:** Meningkatkan kemampuan komputer untuk memahami dan merespons teks manusia, membuat interaksi lebih efisien.\n",
        "  \n",
        "- **Analisis Sentimen:** Memudahkan analisis sentimen dengan merangkum pandangan atau opini yang dominan dari berbagai sumber.\n",
        "\n",
        "Meskipun teks summarization memiliki manfaat besar, tantangan utamanya termasuk mempertahankan keakuratan informasi dan memastikan keseluruhan ringkasan tetap koheren dan bermakna. Seiring dengan perkembangan teknologi pemrosesan bahasa alami, teks summarization terus menjadi fokus penelitian untuk meningkatkan kualitas dan aplikasinya dalam berbagai bidang.\n",
        "\n"
      ],
      "metadata": {
        "id": "-5HryVjFxzeB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengerjakan teks summarization melibatkan beberapa tahapan. Berikut adalah alur umum dalam melakukan teks summarization:\n",
        "\n",
        "1. **Pemahaman Teks Asli:**\n",
        "   - Baca dengan cermat teks asli untuk memahami isi, konteks, dan tujuan utama dari teks tersebut.\n",
        "   - Identifikasi informasi pokok, gagasan utama, dan bagian-bagian kunci yang ingin dicakup dalam ringkasan.\n",
        "\n",
        "2. **Pemilihan Metode Summarization:**\n",
        "   - Tentukan jenis summarization yang paling sesuai: ekstraktif atau abstraktif, berdasarkan kebutuhan dan karakteristik teks.\n",
        "   - Ekstraktif memilih kalimat atau frasa yang penting, sementara abstraktif menciptakan kalimat baru untuk merangkum.\n",
        "\n",
        "3. **Pembuatan Model atau Algoritma:**\n",
        "   - Untuk ekstraktif, buat model atau algoritma untuk menilai pentingnya setiap kalimat berdasarkan kriteria tertentu (frekuensi kata, entitas penting, dll.).\n",
        "   - Untuk abstraktif, kembangkan model yang dapat memahami makna kalimat dan menciptakan ringkasan baru.\n",
        "\n",
        "4. **Pemrosesan Bahasa Alami (NLP):**\n",
        "   - Gunakan teknik pemrosesan bahasa alami untuk memahami dan menguraikan teks.\n",
        "   - Identifikasi struktur kalimat, hubungan antarkalimat, dan makna dari setiap frasa.\n",
        "\n",
        "5. **Ekstraksi atau Pembuatan Ringkasan:**\n",
        "   - Jika ekstraktif, ekstrak kalimat-kalimat atau frasa-frasa yang memiliki nilai penting.\n",
        "   - Jika abstraktif, gunakan model atau algoritma untuk membuat kalimat-kalimat baru yang merangkum informasi utama.\n",
        "\n",
        "6. **Evaluasi dan Koreksi:**\n",
        "   - Lakukan evaluasi terhadap ringkasan yang dihasilkan.\n",
        "   - Pastikan ringkasan mencakup informasi utama dan tetap koheren dengan teks asli.\n",
        "   - Koreksi manual mungkin diperlukan untuk memastikan kualitas ringkasan.\n",
        "\n",
        "7. **Uji Coba dan Evaluasi Performa:**\n",
        "   - Uji coba ringkasan pada berbagai jenis teks dan ukuran untuk mengevaluasi kinerja model atau algoritma.\n",
        "   - Sesuaikan parameter atau model jika diperlukan untuk meningkatkan hasil.\n",
        "\n",
        "8. **Implementasi dan Integrasi:**\n",
        "   - Terapkan hasil ringkasan pada aplikasi atau sistem yang diinginkan, seperti mesin pencari atau asisten virtual.\n",
        "   - Integrasikan teknologi summarization ke dalam proses kerja yang lebih besar jika diperlukan.\n",
        "\n",
        "Alur ini memberikan pandangan umum tentang bagaimana teks summarization dapat dikerjakan. Penting untuk diingat bahwa proses ini dapat bervariasi tergantung pada kompleksitas teks, tujuan ringkasan, dan jenis aplikasi yang diinginkan."
      ],
      "metadata": {
        "id": "tcEr4As73V6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inti alur dari teks summarization adalah data di tokenisasi, dilakukan perhitungan TF-IDF, dihitung kesamaan kosinusnya, visualisasi graph, menampilkan closeenes centrality, menampilkan page rank nya, menampilkan EigenvalueCentrality, dan menamilkan EigenvectorCentrality. Sehingga dapat diketahui hasil summaarizationnya apakah terdapat perbedaan atau tidak."
      ],
      "metadata": {
        "id": "qxdNZVf6g05c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pertama, kita bahas teks Summarization dengan preprocessing. Data yang digunakan menggunakan data berita dari Detik.com dengan metode crawling seperti penjelasan sebelumnya."
      ],
      "metadata": {
        "id": "087UQWm148Ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data**"
      ],
      "metadata": {
        "id": "pNUlw13F4379"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "data yang digunakan adalah data hasil crawling yang di upload ke github. Sehingga, kita tinggal memanggil link githubnya untuk mengakses datanya. Jumlah data yang digunakan hanya satu konten berita.\n",
        "\n",
        "berikut ini codenya ketika kita akan mengakses datanya"
      ],
      "metadata": {
        "id": "5U-a0v3x6Klq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "0fdtHUvp_wMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/alvina-maharani/ppw/main/cobappwbuaru.xlsx'\n",
        "df = pd.read_excel(url)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "jBBkv5py6Juy",
        "outputId": "67233b91-aa6e-454e-c20e-f455122af8c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Judul              Tanggal  \\\n",
              "0  Reog hingga Pentas Tari Meriahkan Karnaval Bud...   19 Agu 2023 15:01    \n",
              "\n",
              "                                                Link  \\\n",
              "0  https://www.detik.com/jateng/berita/d-6884838/...   \n",
              "\n",
              "                                              Konten  \n",
              "0  Kabupaten Klaten menyelenggarakan karnaval bud...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2d3db45-28ab-4961-8268-ff0fa02919e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Judul</th>\n",
              "      <th>Tanggal</th>\n",
              "      <th>Link</th>\n",
              "      <th>Konten</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Reog hingga Pentas Tari Meriahkan Karnaval Bud...</td>\n",
              "      <td>19 Agu 2023 15:01</td>\n",
              "      <td>https://www.detik.com/jateng/berita/d-6884838/...</td>\n",
              "      <td>Kabupaten Klaten menyelenggarakan karnaval bud...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2d3db45-28ab-4961-8268-ff0fa02919e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d2d3db45-28ab-4961-8268-ff0fa02919e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d2d3db45-28ab-4961-8268-ff0fa02919e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code tersebut digunakan untuk membaca data dari file Excel yang terletak di URL tertentu menggunakan Python. Alamat file Excel disimpan dalam variabel `url`, yang kemudian digunakan sebagai parameter dalam fungsi `pd.read_excel(url)` dari library pandas. Proses ini menghasilkan dataframe (df), yang merupakan struktur data tabel yang memuat data dari file Excel. Dataframe ini dapat digunakan untuk melakukan berbagai operasi analisis data, seperti menampilkan sebagian data awal atau akhir, mengakses kolom-kolom tertentu, atau melaksanakan perhitungan statistik. Dengan menggunakan kode tersebut, pengguna dapat dengan mudah membaca dan memanipulasi data dari file Excel yang tersimpan secara online."
      ],
      "metadata": {
        "id": "qRPxBHof-K5R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenisasi**"
      ],
      "metadata": {
        "id": "M9DQaqfy-tng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing yang digunakan dalam teks summarization hanyalah tokenisasi. Meskipun langkah-langkah preprocessing dalam teks summarization seringkali melibatkan lebih dari sekadar tokenisasi, ada argumen untuk mempertimbangkan penggunaan hanya tokenisasi tergantung pada konteks tugas dan sifat dataset. Jika tujuan utama adalah menjaga kesederhanaan model dan efisiensi komputasional, serta datasetnya sudah cukup bersih tanpa gangguan yang signifikan, maka tokenisasi dapat menjadi langkah preprocessing yang memadai. Terutama dalam rangka membangun model ringkasan ekstraktif, di mana informasi kunci dapat diakses melalui token kata, penggunaan hanya tokenisasi dapat meningkatkan keterbacaan, interpretabilitas, dan performa yang memadai. Meski demikian, keputusan ini sebaiknya tetap didasarkan pada evaluasi khusus dataset dan tujuan tugas yang ingin dicapai."
      ],
      "metadata": {
        "id": "xTpZIU1c-wTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut code proses tokenisasinya.."
      ],
      "metadata": {
        "id": "bb_N7HT3lXC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "df['Konten'] = df['Konten'].apply(lambda x: sent_tokenize(str(x)))\n",
        "df"
      ],
      "metadata": {
        "id": "Q2ybBLnVlTvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**TF-IDF**"
      ],
      "metadata": {
        "id": "wN96cF-cl2NS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF (Term Frequency-Inverse Document Frequency) adalah metode statistik yang digunakan dalam teks summarization untuk menilai kepentingan relatif suatu kata dalam suatu dokumen atau korpus. Rumus TF-IDF menggabungkan Term Frequency (TF), yang mengukur seberapa sering suatu kata muncul dalam dokumen, dengan Inverse Document Frequency (IDF), yang mempertimbangkan seberapa umum atau unik kata tersebut dalam seluruh korpus. Penggunaan TF-IDF dalam teks summarization memberikan bobot pada kata-kata berdasarkan keunikannya dan membantu mengidentifikasi kata-kata kunci serta menekankan informasi penting. Selain itu, TF-IDF dapat digunakan untuk mereduksi dimensi dalam representasi teks, memilih fitur-fitur informatif, dan menyediakan landasan bagi ekstraksi informasi kunci dalam pembuatan ringkasan. Dengan memperhatikan frekuensi dan distribusi kata-kata, TF-IDF membantu meningkatkan kualitas representasi teks, memfasilitasi proses ekstraksi informasi, dan menyokong tugas teks summarization secara efektif.\n",
        "\n",
        "berikut code untuk tf idf"
      ],
      "metadata": {
        "id": "BAqWZj7Yl7oO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "df_tampilan = pd.DataFrame(df_tampilan)\n",
        "# Hitung TF untuk setiap kata dalam setiap kalimat\n",
        "tf_values = []\n",
        "for index, row in df_tampilan.iterrows():\n",
        "    tf_dict = {}\n",
        "    for word in row['kalimat'].split():\n",
        "        tf_dict[word] = row['kalimat'].split().count(word) / row['jumlah_kata']\n",
        "    tf_values.append(tf_dict)\n",
        "\n",
        "# Menghitung IDF untuk setiap kata\n",
        "idf_values = {}\n",
        "total_documents = len(df_tampilan)\n",
        "for tf in tf_values:\n",
        "    for word in tf:\n",
        "        if word in idf_values:\n",
        "            idf_values[word] += 1\n",
        "        else:\n",
        "            idf_values[word] = 1\n",
        "\n",
        "# Menghitung TF-IDF\n",
        "tfidf_values = []\n",
        "for tf in tf_values:\n",
        "    tfidf_dict = {}\n",
        "    for word, tf_value in tf.items():\n",
        "        tfidf_dict[word] = tf_value * math.log(total_documents / (1 + idf_values[word]))\n",
        "    tfidf_values.append(tfidf_dict)\n",
        "\n",
        "# Konversi list of dicts ke dalam DataFrame\n",
        "df_tfidf = pd.DataFrame(tfidf_values)\n",
        "df_tfidf.fillna(0, inplace=True)\n",
        "\n",
        "# Tampilkan hasil TF-IDF DataFrame\n",
        "df_tfidf"
      ],
      "metadata": {
        "id": "ZxQ3JxWkmXX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode tersebut menggunakan Python dan beberapa pustaka seperti pandas dan scikit-learn untuk menghitung Term Frequency-Inverse Document Frequency (TF-IDF) dari suatu dataset teks yang disimpan dalam DataFrame. Pertama, kode menghitung Term Frequency (TF) untuk setiap kata dalam setiap kalimat di DataFrame, diikuti dengan perhitungan Inverse Document Frequency (IDF) untuk setiap kata. Selanjutnya, kode menggabungkan nilai TF dan IDF untuk menghitung nilai TF-IDF. Hasilnya disajikan dalam DataFrame baru (df_tfidf) di mana setiap kolom mewakili kata-kata unik, dan setiap baris mewakili dokumen atau kalimat, dengan nilai-nilai TF-IDF sebagai bobotnya. Kode ini memberikan representasi numerik yang menggambarkan pentingnya setiap kata dalam konteks keseluruhan dataset, dan dapat digunakan sebagai langkah awal dalam analisis teks atau tugas seperti klasifikasi dokumen atau pemodelan topik."
      ],
      "metadata": {
        "id": "t0yL0lS5mns7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cosine Similarity**"
      ],
      "metadata": {
        "id": "M2r-BQcSmpjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine similarity adalah metrik yang digunakan dalam teks summarization untuk mengukur sejauh mana dua vektor teks mirip berdasarkan sudut cosine antara mereka. Dalam konteks ini, vektor teks direpresentasikan oleh nilai TF-IDF (Term Frequency-Inverse Document Frequency) dari kata-kata dalam dokumen atau kalimat. Cosine similarity mengukur kesamaan antara dua vektor dengan menghitung cosinus dari sudut yang terbentuk oleh vektor-vektor tersebut dalam ruang vektor. Nilai cosine similarity berkisar antara 0 (vektor sepenuhnya ortogonal, tidak ada kesamaan) hingga 1 (vektor sepenuhnya sejajar, kesamaan maksimum). Dalam konteks summarization, cosine similarity digunakan untuk mengevaluasi seberapa mirip suatu kalimat atau dokumen dengan kalimat atau dokumen lainnya. Metrik ini memungkinkan model untuk menentukan tingkat relevansi atau kemiripan antara teks, dan hasilnya dapat digunakan untuk memilih atau mengurutkan kalimat-kalimat yang paling relevan dalam proses pembuatan ringkasan. Semakin tinggi nilai cosine similarity, semakin mirip atau relevan kedua vektor tersebut, yang dapat menghasilkan ringkasan yang lebih akurat dan informatif."
      ],
      "metadata": {
        "id": "Tq33JskdmzrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agar lebih mudah memahami perhitungan cosine similarity perhatikan hal berikut :\n",
        "\n",
        "Bayangkan kita memiliki dua daftar kata-kata yang mewakili dua kalimat atau dokumen. Untuk mengukur seberapa mirip keduanya, kita menggunakan cosine similarity. Langkah-langkahnya adalah sebagai berikut:\n",
        "\n",
        "1. **Hitung Jumlah Kalikan:**\n",
        "   - Hitung hasil penjumlahan dari perkalian setiap kata pada posisi yang sama dari kedua daftar kata.\n",
        "\n",
        "2. **Hitung Panjang (Magnitude):**\n",
        "   - Hitung panjang (magnitude) dari masing-masing daftar kata.\n",
        "   - Panjangnya dihitung dengan menjumlahkan kuadrat dari setiap kata dan mengakarkan hasilnya.\n",
        "\n",
        "3. **Hitung Cosine Similarity:**\n",
        "   - Bagi hasil penjumlahan kalikan tadi dengan hasil perkalian panjang kedua daftar kata.\n",
        "   - Ini memberikan nilai cosine similarity antara 0 (tidak mirip) dan 1 (sangat mirip).\n",
        "\n",
        "Contoh:\n",
        "- Daftar kata pertama: [3, 1, 2]\n",
        "- Daftar kata kedua: [1, 2, 0]\n",
        "\n",
        "1. Hitung Jumlah Kalikan: $ (3 \\times 1) + (1 \\times 2) + (2 \\times 0) = 5 $\n",
        "2. Hitung Panjang:\n",
        "   - Panjang Daftar Pertama: $ \\sqrt{3^2 + 1^2 + 2^2} = \\sqrt{14} $\n",
        "   - Panjang Daftar Kedua: $ \\sqrt{1^2 + 2^2 + 0^2} = \\sqrt{5} $\n",
        "3. Hitung Cosine Similarity: $ \\frac{5}{\\sqrt{14} \\times \\sqrt{5}} \\approx 0.75 $\n",
        "\n",
        "Hasilnya adalah sekitar 0.75, yang berarti kedua daftar kata tersebut cukup mirip. Semakin mendekati 1, semakin mirip keduanya."
      ],
      "metadata": {
        "id": "jJ6f4nr1nWfW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "berikut implementasi dalam bentuk code nya"
      ],
      "metadata": {
        "id": "R428QAZBn4jY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "df_tf_idf = pd.DataFrame(df_tfidf)\n",
        "df_tf_idf = df_tf_idf.fillna(0)\n",
        "\n",
        "tfidf_matrix = df_tf_idf.to_numpy()\n",
        "\n",
        "# Menghitung kesamaan kosinus\n",
        "similarity_matrix = cosine_similarity(tfidf_matrix)\n",
        "df_tf_idf = pd.DataFrame(similarity_matrix)\n",
        "\n",
        "kalimat = [\"Kalimat \" + str(i) for i in range(1, len(similarity_matrix) + 1)]\n",
        "df_tf_idf = df_tf_idf.set_axis(kalimat, axis=0)\n",
        "df_tf_idf = df_tf_idf.set_axis(kalimat, axis=1)\n",
        "\n",
        "df_tf_idf"
      ],
      "metadata": {
        "id": "JaVir_4nn6-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode ini menggunakan pustaka pandas dan scikit-learn untuk menghitung cosine similarity antara kalimat-kalimat dalam suatu dataset teks yang telah diubah menjadi representasi TF-IDF. Pertama, DataFrame df_tfidf yang berisi nilai-nilai TF-IDF diisi dengan nilai 0 untuk menggantikan nilai-nilai NaN. Selanjutnya, matriks TF-IDF diubah menjadi bentuk array NumPy. Kemudian, menggunakan fungsi cosine_similarity dari scikit-learn, matriks kesamaan kosinus dihitung dari matriks TF-IDF. Hasilnya disimpan dalam DataFrame baru df_tf_idf, yang berfungsi sebagai matriks kesamaan kosinus antar kalimat. Nama-nama kalimat ditambahkan ke DataFrame untuk memudahkan identifikasi, dan DataFrame akhirnya berisi nilai-nilai cosine similarity antara setiap pasangan kalimat dalam dataset teks. Code ini berguna dalam analisis kesamaan antar kalimat, seperti dalam proses pengelompokan atau penentuan relevansi kalimat untuk tugas seperti teks summarization."
      ],
      "metadata": {
        "id": "OweP-R-S6a2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualisasi Graph**"
      ],
      "metadata": {
        "id": "EpwGypni6etZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisasi graf dari cosine similarity dengan nilai bulatan (nodes) dan threshold merupakan metode yang efektif untuk memahami dan menganalisis hubungan kesamaan antar elemen dalam dataset teks. Dalam graf ini, setiap elemen, seperti kalimat atau dokumen, direpresentasikan sebagai simpul, sementara sisi antara simpul-simpul tersebut mencerminkan nilai kesamaan kosinus antara elemen-elemen tersebut. Pemberian warna dan ketebalan pada sisi graf dapat memberikan visualisasi yang jelas tentang tingkat kesamaan: nilai cosine similarity yang tinggi dapat ditandai dengan warna yang lebih gelap atau sisi yang lebih tebal, sedangkan nilai yang rendah dapat ditandai dengan warna yang lebih terang atau sisi yang lebih tipis. Penambahan label pada setiap simpul memudahkan identifikasi elemen yang direpresentasikan. Dengan menetapkan threshold atau ambang batas, hanya sisi dengan nilai kesamaan di atas ambang batas yang diwakili dalam graf, memungkinkan fokus pada hubungan yang dianggap signifikan. Visualisasi ini menjadi alat yang berguna dalam menganalisis struktur data teks, membantu pemahaman pola dan kelompok kesamaan, terutama dalam konteks tugas seperti teks summarization atau pengelompokan teks."
      ],
      "metadata": {
        "id": "Rx7TqSCY7AAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Page Rank**"
      ],
      "metadata": {
        "id": "wm8EPxwB7Dk4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PageRank adalah algoritma yang digunakan oleh mesin pencari, terutama oleh Google, untuk menilai dan mengurutkan halaman web berdasarkan tingkat otoritas dan relevansinya. Konsepnya mirip dengan cara kita memberi peringkat populeritas atau pentingnya halaman web. Bayangkan setiap halaman web sebagai orang dalam sebuah jaringan sosial. Jika banyak orang (halaman web lain) menghubungi atau memberi suara pada seseorang (halaman web), orang itu dianggap penting. Dengan PageRank, setiap halaman web memberikan \"suara\" dalam bentuk tautan ke halaman lain. Semakin banyak tautan masuk yang dimiliki halaman web, semakin tinggi peringkatnya. Tetapi tidak semua suara dianggap sama. Suara dari halaman yang memiliki peringkat tinggi lebih berharga daripada suara dari halaman dengan peringkat rendah. Dengan cara ini, PageRank membantu mesin pencari menentukan halaman web mana yang paling penting dan relevan, sehingga hasil pencarian yang diberikan kepada pengguna menjadi lebih baik."
      ],
      "metadata": {
        "id": "NFHrqZwh7W1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "untuk lebih memahami page rank, perhatikan perhitungan berikut :    \n",
        "\n",
        "PageRank dihitung menggunakan algoritma yang mempertimbangkan jumlah dan kualitas tautan yang mengarah ke suatu halaman web. Secara matematis, rumus PageRank dapat dijelaskan sebagai berikut:\n",
        "\n",
        "$ \\text{PR}(A) = (1 - d) + d \\left( \\frac{\\text{PR}(B)}{L(B)} + \\frac{\\text{PR}(C)}{L(C)} + \\ldots + \\frac{\\text{PR}(N)}{L(N)} \\right) $\n",
        "\n",
        "Di sini:\n",
        "- $\\text{PR}(A)$ adalah PageRank dari halaman web A.\n",
        "- $(d)$ adalah faktor damping (biasanya diatur sekitar 0,85), yang merepresentasikan probabilitas bahwa pengguna akan mengikuti tautan daripada menavigasi ke halaman acak.\n",
        "- $\\text{PR}(B)$, $\\text{PR}(C)$, ..., $\\text{PR}(N)$ adalah PageRank dari halaman-halaman yang terhubung ke halaman A.\n",
        "- $L(B)$, $L(C)$, ..., $L(N)$ adalah jumlah tautan keluar dari halaman-halaman B, C, ..., N.\n",
        "\n",
        "Mari kita ilustrasikan ini dengan contoh sederhana:\n",
        "\n",
        "1. Ada tiga halaman web: A, B, dan C.\n",
        "2. Semua halaman memiliki PageRank awal yang sama (misalnya, 1/3).\n",
        "3. Halaman B dan C memiliki tautan ke halaman A.\n",
        "\n",
        "Mari kita hitung PageRank untuk halaman A:\n",
        "\n",
        "$ \\text{PR}(A) = (1 - 0.85) + 0.85 \\left( \\frac{1/3}{1} + \\frac{1/3}{1} \\right) $\n",
        "\n",
        "$\\text{PR}(A) = 0.15 + 0.85 \\left( \\frac{2/3}{1} \\right) $\n",
        "\n",
        "$ \\text{PR}(A) = 0.15 + 0.85 \\times \\frac{2}{3} $\n",
        "\n",
        "$ \\text{PR}(A) = 0.15 + 0.566666... $\n",
        "\n",
        "$ \\text{PR}(A) \\approx 0.716 $\n",
        "\n",
        "Ini adalah perhitungan sederhana untuk mengilustrasikan konsep PageRank. Dalam praktiknya, algoritma PageRank diiterasi secara berulang hingga konvergensi untuk mendapatkan nilai akhir PageRank yang lebih akurat.\n",
        "\n",
        "berikut code untuk page rank"
      ],
      "metadata": {
        "id": "RN21hhTd7ZU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hitung PageRank\n",
        "pagerank = nx.pagerank(G)\n",
        "\n",
        "# Menampilkan Closeness Centrality\n",
        "print(\"PageRank:\")\n",
        "for node, rank in pagerank.items():\n",
        "    print(f\"Node {node}: {rank}\")\n",
        "\n",
        "# Menampilkan 3 kalimat dengan PageRank tertinggi\n",
        "sorted_pagerank = sorted(pagerank.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"=============================\")\n",
        "print(\"Top 3 sentences based on PageRank:\")\n",
        "for node, rank in sorted_pagerank[:3]:\n",
        "    print(df_tampilan['kalimat'].iloc[node])\n",
        "\n",
        "print(\"=============================\")\n",
        "print(\"Top 3 node based on PageRank:\")\n",
        "for node, rank in sorted_pagerank[:3]:\n",
        "    print(f\"Node {node} dengan PageRank {rank:.4f}\")\n",
        "\n",
        "#sorted_pagerank = sorted(pagerank.items(), key=lambda x: x[1], reverse=True)"
      ],
      "metadata": {
        "id": "QJMgIgRu8-hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode tersebut menggunakan pustaka NetworkX untuk menghitung PageRank dari graf yang diberikan. Pertama, PageRank dihitung menggunakan fungsi nx.pagerank(G), di mana G adalah graf yang mewakili hubungan antar elemen (misalnya, kalimat dalam dataset). Hasil PageRank kemudian ditampilkan dengan mencetak nilai PageRank untuk setiap elemen dalam graf.\n",
        "\n",
        "Selanjutnya, kode mengurutkan elemen-elemen berdasarkan PageRank secara menurun, dan menampilkan 3 kalimat dengan PageRank tertinggi dari DataFrame yang disimpan di df_tampilan. Ini membantu dalam menyoroti kalimat-kalimat yang dianggap paling penting berdasarkan algoritma PageRank.\n",
        "\n",
        "Terakhir, kode mencetak informasi tentang 3 elemen (node) dengan PageRank tertinggi, termasuk nomor node dan nilai PageRank. Ini memberikan gambaran tentang elemen-elemen yang dianggap paling otoritatif atau penting dalam graf berdasarkan algoritma PageRank."
      ],
      "metadata": {
        "id": "heVr2XaX9rL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Closseness Centrality**\n",
        "\n"
      ],
      "metadata": {
        "id": "n6FmtVvw-7qa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Closeness centrality adalah salah satu metrik sentralitas dalam jaringan yang digunakan untuk mengukur seberapa dekat suatu node dengan node lainnya dalam graf. Dalam konteks teks summarization, closeness centrality dapat diaplikasikan pada representasi graf dari hubungan antara kalimat-kalimat dalam suatu teks. Metrik ini memberikan informasi tentang seberapa mudah suatu kalimat dapat diakses oleh kalimat-kalimat lain dalam teks tersebut.\n",
        "\n",
        "Dalam implementasi kode yang Anda berikan, closeness centrality dihitung untuk setiap kalimat dalam graf representasi hubungan kalimat (misalnya, graf kalimat yang terhubung berdasarkan kosinus similarity). Kalimat yang memiliki closeness centrality tinggi cenderung menjadi pusat komunikasi dalam teks, karena lebih dekat dengan kalimat-kalimat lainnya.\n",
        "\n",
        "Dalam konteks teks summarization, closeness centrality dapat membantu mengidentifikasi kalimat-kalimat yang secara esensial \"menghubungkan\" atau merepresentasikan inti informasi dalam teks. Kalimat-kalimat ini memiliki potensi untuk menjadi penting dalam proses pembuatan ringkasan karena mereka memiliki keterkaitan yang erat dengan kalimat-kalimat lainnya. Memilih kalimat-kalimat dengan closeness centrality tinggi dapat membantu dalam mengekstraksi inti informasi atau gagasan utama dari teks, yang merupakan langkah kritis dalam proses teks summarization. Oleh karena itu, closeness centrality menjadi salah satu faktor yang dapat digunakan untuk menentukan relevansi dan kontribusi kalimat dalam memahami struktur dan makna keseluruhan teks."
      ],
      "metadata": {
        "id": "H_ZaLKPL_gio"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Closeness centrality mengukur seberapa dekat suatu node (kalimat dalam konteks teks summarization) dengan semua node lainnya dalam graf. Rumusnya dapat dijelaskan sebagai:\n",
        "\n",
        "$ C(x) = \\frac{1}{\\sum_{y \\neq x} d(x, y)} $\n",
        "\n",
        "Di sini:\n",
        "- $ C(x) $ adalah closeness centrality dari node $ x $ (kalimat).\n",
        "- $ d(x, y) $ adalah jarak terpendek (misalnya, jumlah tautan atau kesamaan kosinus) antara node $ x $ dan node $ y $.\n",
        "\n",
        "Closeness centrality diperoleh dengan membalikkan jumlah jarak terpendek dari node $ x $ ke semua node lainnya. Semakin kecil nilai $ \\sum_{y \\neq x} d(x, y) $, semakin besar nilai closeness centrality-nya. Dalam konteks teks summarization, kalimat-kalimat dengan closeness centrality yang tinggi cenderung menjadi pusat atau penting dalam merangkum informasi karena dekat dengan kalimat-kalimat lainnya dalam teks."
      ],
      "metadata": {
        "id": "25KelOvL_2JH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mari kita lihat studi kasus sederhana untuk menghitung closeness centrality dari beberapa kalimat dalam suatu teks. Anggaplah kita memiliki tiga kalimat:\n",
        "\n",
        "1. \"Hewan peliharaan adalah teman yang baik.\"\n",
        "2. \"Anjing dan kucing adalah contoh hewan peliharaan.\"\n",
        "3. \"Setiap orang harus memberi makan dan merawat hewan peliharaan dengan baik.\"\n",
        "\n",
        "Langkah-langkahnya sebagai berikut:\n",
        "\n",
        "1. **Buat Graf Representasi Hubungan:**\n",
        "   - Hubungan antar kalimat dapat direpresentasikan dengan graf, di mana setiap node adalah kalimat, dan ada sisi (edge) antara dua kalimat jika ada hubungan atau kesamaan antara keduanya.\n",
        "\n",
        "   $\n",
        "   \\begin{matrix}\n",
        "   & \\text{1} & \\text{2} & \\text{3} \\\\\n",
        "   \\text{1} & - & \\checkmark & \\checkmark \\\\\n",
        "   \\text{2} & \\checkmark & - & \\checkmark \\\\\n",
        "   \\text{3} & \\checkmark & \\checkmark & -\n",
        "   \\end{matrix}\n",
        "   $\n",
        "\n",
        "   Di sini, tanda $\\checkmark$ menunjukkan adanya hubungan atau kesamaan antara dua kalimat.\n",
        "\n",
        "2. **Hitung Jarak Terpendek:**\n",
        "   - Hitung jarak terpendek dari setiap kalimat ke kalimat lainnya. Misalnya, dapat menggunakan jumlah tautan atau kesamaan kosinus sebagai metrik jarak.\n",
        "\n",
        "   $\n",
        "   \\begin{matrix}\n",
        "   & \\text{1} & \\text{2} & \\text{3} \\\\\n",
        "   \\text{1} & - & 1 & 1 \\\\\n",
        "   \\text{2} & 1 & - & 1 \\\\\n",
        "   \\text{3} & 1 & 1 & -\n",
        "   \\end{matrix}\n",
        "   $\n",
        "\n",
        "3. **Hitung Closeness Centrality:**\n",
        "   - Gunakan rumus closeness centrality untuk setiap kalimat:\n",
        "\n",
        "  $\n",
        "   \\begin{align*}\n",
        "   C(1) &= \\frac{1}{1+1} = \\frac{1}{2} \\\\\n",
        "   C(2) &= \\frac{1}{1+1} = \\frac{1}{2} \\\\\n",
        "   C(3) &= \\frac{1}{1+1} = \\frac{1}{2}\n",
        "   \\end{align*}\n",
        "   $\n",
        "   \n",
        "   Dalam kasus ini, semua kalimat memiliki closeness centrality yang sama, yaitu $ \\frac{1}{2} $.\n",
        "\n",
        "Dalam praktiknya, metrik jarak dan kompleksitas graf yang lebih besar dapat mempengaruhi perhitungan closeness centrality. Studi kasus sederhana ini memberikan gambaran tentang bagaimana langkah-langkah dasar dapat diambil untuk menghitung closeness centrality dalam konteks teks summarization.\n",
        "\n",
        "berikut code untuk closeness centrality :"
      ],
      "metadata": {
        "id": "6sF1nY_LAz2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghitung closeness centrality dari graph\n",
        "closeness = nx.closeness_centrality(G)\n",
        "\n",
        "# Menampilkan closeness centrality\n",
        "print(\"Closeness Centrality:\")\n",
        "for node, closeness_value in closeness.items():\n",
        "    print(f\"Node {node}: {closeness_value}\")\n",
        "\n",
        "# Menampilkan 3 kalimat dengan PageRank tertinggi\n",
        "sorted_pagerank = sorted(closeness.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"=============================\")\n",
        "print(\"Top 3 sentences based on closeness centrality:\")\n",
        "for node, rank in sorted_pagerank[:3]:\n",
        "    print(df_tampilan['kalimat'].iloc[node])\n",
        "\n",
        "print(\"=============================\")\n",
        "print(\"Top 3 node based on closeness centrality:\")\n",
        "for node, rank in sorted_pagerank[:3]:\n",
        "    print(f\"Node {node} dengan PageRank {rank:.4f}\")"
      ],
      "metadata": {
        "id": "nbSDNSkaD23H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code tersebut menggunakan pustaka NetworkX untuk menghitung closeness centrality dari suatu graf (G) yang mewakili hubungan antar elemen, seperti kalimat dalam teks. Pertama, closeness centrality dihitung dengan menggunakan fungsi nx.closeness_centrality(G). Hasilnya disimpan dalam variabel closeness. Selanjutnya, nilai closeness centrality untuk setiap elemen (node) dalam graf ditampilkan dengan mencetaknya.\n",
        "\n",
        "Selanjutnya, kode mengurutkan elemen-elemen berdasarkan closeness centrality secara menurun dan menampilkan 3 kalimat dengan closeness centrality tertinggi dari DataFrame yang disimpan di df_tampilan. Ini membantu menyoroti kalimat-kalimat yang dianggap paling sentral atau penting dalam representasi graf.\n",
        "\n",
        "Terakhir, kode mencetak informasi tentang 3 elemen (node) dengan closeness centrality tertinggi, termasuk nomor node dan nilai closeness centrality-nya. Ini memberikan gambaran tentang elemen-elemen yang dianggap paling sentral atau dekat dengan elemen lainnya dalam graf berdasarkan closeness centrality."
      ],
      "metadata": {
        "id": "PbDgCHu3FeOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Eigenvector Centrality**"
      ],
      "metadata": {
        "id": "BfPibmKXHYA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eigenvector Centrality adalah metrik sentralitas yang digunakan dalam analisis jaringan untuk mengukur seberapa penting atau sentral suatu node dalam konteks keterhubungan dengan node-node yang juga memiliki sentralitas tinggi. Dalam teks summarization, Eigenvector Centrality dapat diaplikasikan pada representasi graf hubungan antar kalimat atau dokumen.\n",
        "\n",
        "Rumus Eigenvector Centrality untuk suatu node $v$ dalam graf adalah sebagai berikut:\n",
        "\n",
        "$ C(v) = \\frac{1}{\\lambda} \\sum_{u \\in N(v)} A(u, v) \\cdot C(u) $\n",
        "\n",
        "Di sini:\n",
        "- $ C(v) $ adalah Eigenvector Centrality dari node $v$.\n",
        "- $ N(v) $ adalah himpunan tetangga dari node $v$, yaitu node-node yang terhubung langsung dengan $v$.\n",
        "- $ A(u, v) $ adalah elemen matriks ketetanggaan yang menunjukkan apakah terdapat sisi (edge) antara node $u$ dan $v$.\n",
        "- $ {λ} $ adalah nilai eigenvalue utama (dominan) dari matriks ketetanggaan.\n",
        "\n",
        "Dalam konteks teks summarization, Eigenvector Centrality dapat membantu mengidentifikasi kalimat-kalimat atau dokumen-dokumen yang secara struktural penting dalam jaringan kalimat atau dokumen. Kalimat atau dokumen dengan Eigenvector Centrality yang tinggi cenderung menjadi pusat atau memiliki keterkaitan yang kuat dengan kalimat atau dokumen lain yang juga dianggap penting. Dengan memilih kalimat-kalimat atau dokumen-dokumen ini, kita dapat fokus pada inti informasi atau gagasan utama dalam teks saat melakukan proses summarization. Sehingga, Eigenvector Centrality menjadi alat yang bermanfaat untuk memahami dan mengekstrak elemen-elemen krusial dalam teks."
      ],
      "metadata": {
        "id": "t2yEditjHl4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mari kita buat studi kasus sederhana untuk menghitung Eigenvector Centrality pada suatu graf teks. Anggaplah kita memiliki tiga kalimat:\n",
        "\n",
        "1. \"Hewan peliharaan adalah teman yang baik.\"\n",
        "2. \"Anjing dan kucing adalah contoh hewan peliharaan.\"\n",
        "3. \"Setiap orang harus memberi makan dan merawat hewan peliharaan dengan baik.\"\n",
        "\n",
        "Langkah-langkahnya sebagai berikut:\n",
        "\n",
        "1. **Buat Graf Representasi Hubungan:**\n",
        "   - Hubungan antar kalimat dapat direpresentasikan dengan graf, di mana setiap node adalah kalimat, dan ada sisi (edge) antara dua kalimat jika ada hubungan atau kesamaan antara keduanya.\n",
        "\n",
        "   $\n",
        "   \\begin{matrix}\n",
        "   & \\text{1} & \\text{2} & \\text{3} \\\\\n",
        "   \\text{1} & - & 1 & 1 \\\\\n",
        "   \\text{2} & 1 & - & 1 \\\\\n",
        "   \\text{3} & 1 & 1 & -\n",
        "   \\end{matrix}\n",
        "   $\n",
        "\n",
        "   Di sini, tanda $1$ menunjukkan adanya hubungan atau kesamaan antara dua kalimat.\n",
        "\n",
        "2. **Hitung Eigenvector Centrality:**\n",
        "   - Dengan menggunakan rumus Eigenvector Centrality, kita lakukan iterasi untuk menghitung sentralitas eigenvector untuk setiap kalimat.\n",
        "\n",
        "   $ C(1) = \\frac{1}{\\lambda} \\times (1 \\times C(2) + 1 \\times C(3)) $\n",
        "   $ C(2) = \\frac{1}{\\lambda} \\times (1 \\times C(1) + 1 \\times C(3)) $\n",
        "   $ C(3) = \\frac{1}{\\lambda} \\times (1 \\times C(1) + 1 \\times C(2)) $\n",
        "\n",
        "   Iterasi ini dilakukan hingga nilai Eigenvector Centrality konvergen.\n",
        "\n",
        "3. **Normalisasi Nilai:**\n",
        "   - Setelah nilai Eigenvector Centrality konvergen, normalisasikan nilainya sehingga total nilai eigenvector adalah 1.\n",
        "\n",
        "   $ \\sum_{i} C(i) = 1 $\n",
        "\n",
        "Dalam praktiknya, proses ini dapat diimplementasikan dengan menggunakan algoritma numerik atau pustaka komputasi seperti NumPy. Studi kasus ini memberikan gambaran umum tentang cara menghitung Eigenvector Centrality secara manual pada sebuah graf teks sederhana.\n",
        "\n"
      ],
      "metadata": {
        "id": "df0gDJylFnaf"
      }
    }
  ]
}